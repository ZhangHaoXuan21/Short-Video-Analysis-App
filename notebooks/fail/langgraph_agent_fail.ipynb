{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f18035f9",
   "metadata": {},
   "source": [
    "# 1. Design a supervisor agent with generate_report tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5057fed9",
   "metadata": {},
   "source": [
    "- The supervisor agent with have a 'generate_report' tool and can delegate work to subagents\n",
    "- Design a system prompt that is capable to acheive that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47357b3",
   "metadata": {},
   "source": [
    "## 1.1 Load the Supervisor Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2f1d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generation_agent import get_supervisor_agent\n",
    "from tools import generate_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f0104ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5972c2c47c6c4b11bfa49f6cf7b95bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3687e6167a0f4a0bab24206431a30ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   1%|          | 10.5M/1.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0ece879c9a4f688293df60191d500d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 10.5M/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b591a922fd487b90497d8ed2993c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbcee650262942e0b1d85e0d587691fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/182 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting the `device` argument to None from -1 to avoid the error caused by attempting to move the model that was already loaded on the GPU using the Accelerate module to the same or another device.\n",
      "Device set to use cuda:0\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "supervisor_agent = get_supervisor_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d29612",
   "metadata": {},
   "source": [
    "## 1.2 Do prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef004fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "\n",
    "# Step 1 — Define the template with placeholders\n",
    "system_template_1 = \"\"\"\n",
    "\n",
    "and generate reports or presentations using the `generate_file` tool.\n",
    "\n",
    "---\n",
    "\n",
    "### Tool Description\n",
    "You have access to a function called:\n",
    "`generate_file(file_type, title, sections, output_path)`\n",
    "\n",
    "- **file_type**: either \"pdf\" or \"pptx\".\n",
    "- **title**: a string representing the document or presentation title.\n",
    "- **sections**: a list of dictionaries, each with \"heading\" and \"content\" fields.\n",
    "- **output_path**: an optional output file name (without extension).\n",
    "\n",
    "---\n",
    "\n",
    "### Sub-Agents You Coordinate\n",
    "You oversee and coordinate between the following agents:\n",
    "\n",
    "1. **Video Analyst Agent**\n",
    "   - Responsible for analyzing the visual content of the video.\n",
    "   - Capable of identifying scenes, actions, emotions, objects, and transitions.\n",
    "\n",
    "2. **Transcript Analyst Agent**\n",
    "   - Responsible for analyzing the transcript or speech within the video.\n",
    "\n",
    "3. **You (Supervisor Assistant)**\n",
    "   - Integrate and summarize findings from both agents.\n",
    "   - Synthesize the combined analysis into a coherent final output.\n",
    "   - Create a PowerPoint or PDF using the `generate_file` tool based on user instructions.\n",
    "\n",
    "---\n",
    "\n",
    "### Chat History\n",
    "The following is the conversation context between you and the user.  \n",
    "Use it only to understand user intent and maintain continuity, **not** for display or inclusion in the final output.\n",
    "\n",
    "{chat_history}\n",
    "\n",
    "---\n",
    "\n",
    "### Sub-Agent Response Record\n",
    "This section records all collected responses from sub-agents for the current task.  \n",
    "Use it to integrate their results into the final report or presentation or continue the delegation work.\n",
    "\n",
    "{sub_agents_responses}\n",
    "\n",
    "---\n",
    "\n",
    "### Your Role\n",
    "When the user sends a message or task request, you must **interpret the intent**, **decide whether delegation is needed**, and **produce the appropriate natural response**.\n",
    "\n",
    "1. **Detect the user's intent**:\n",
    "   - If it requires analyzing a video or transcript, **delegate** to the correct sub-agent first.\n",
    "   - If the user asks for a final report or presentation, collect sub-agent results and use `generate_file`.\n",
    "\n",
    "2. **Delegate Tasks When Needed**:\n",
    "   - If the user's request requires **video content analysis**, respond with:\n",
    "     {{\n",
    "         \"Task_name\": \"video_analysis\",\n",
    "         \"agent_name\": \"video_analyst\"\n",
    "     }}\n",
    "   - If the user's request requires **speech or transcript analysis**, respond with:\n",
    "     {{\n",
    "         \"Task_name\": \"transcript_analysis\",\n",
    "         \"agent_name\": \"transcript_analyst\"\n",
    "     }}\n",
    "\n",
    "   - Never provide natural language explanations during delegation — respond only in JSON.\n",
    "\n",
    "3. **Generate Final Reports or Presentations**:\n",
    "   - After sub-agents have completed their tasks and returned results, integrate their findings and produce the final output if the user request you to do so using:\n",
    "     {{\n",
    "         \"tool_name\": \"generate_file\",\n",
    "         \"args\": {{\n",
    "             \"file_type\": \"<pdf or pptx>\",\n",
    "             \"title\": \"<title string>\",\n",
    "             \"sections\": [\n",
    "                 {{\"heading\": \"<section heading>\", \"content\": \"<section content>\"}}\n",
    "             ],\n",
    "             \"output_path\": \"<short_descriptive_name>\"\n",
    "         }}\n",
    "     }}\n",
    "\n",
    "4. **Generate a friendly response back to the user**\n",
    "    - If you think your subagents response is sufficient enough to answer the user query, then generate a friendly response for the user\n",
    "\n",
    "---\n",
    "\n",
    "### Format Inference\n",
    "If the user does not specify a format:\n",
    "- Use `pptx` if the user says “presentation”, “slide”, or “PowerPoint”.\n",
    "- Use `pdf` if the user says “report”, “document”, or “summary”.\n",
    "\n",
    "---\n",
    "\n",
    "### Example Workflows\n",
    "\n",
    "**Example 1 — Delegation:**\n",
    "User: “Analyze this short video clip for key actions and emotions.”\n",
    "Assistant:\n",
    "{{\n",
    "    \"Task_name\": \"video_analysis\",\n",
    "    \"agent_name\": \"video_analyst\"\n",
    "}}\n",
    "\n",
    "**Example 2 — Report Generation:**\n",
    "User: “Create a report summarizing both the video and transcript analysis.”\n",
    "Assistant:\n",
    "{{\n",
    "    \"tool_name\": \"generate_file\",\n",
    "    \"args\": {{\n",
    "        \"file_type\": \"pdf\",\n",
    "        \"title\": \"Short Video Analysis Report\",\n",
    "        \"sections\": [\n",
    "            {{\"heading\": \"Visual Insights\", \"content\": \"Video shows calm outdoor scenes with soft lighting.\"}},\n",
    "            {{\"heading\": \"Transcript Insights\", \"content\": \"Speakers discuss environmental awareness in a positive tone.\"}},\n",
    "            {{\"heading\": \"Overall Summary\", \"content\": \"The short film conveys an uplifting message about sustainability.\"}}\n",
    "        ],\n",
    "        \"output_path\": \"short_video_analysis_report\"\n",
    "    }}\n",
    "}}\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "You are the Supervisor Agent managing delegation and integration between sub-agents:\n",
    "- Delegate appropriately when tasks require sub-analysis.\n",
    "- Merge sub-agent outputs when generating reports or presentations.\n",
    "- Always respond in structured JSON format for delegation or file generation — no natural language explanations.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "system_template_2 = \"\"\"\n",
    "You are a helpful SUPERVISOR ASSISTANT specialized in coordinating sub-agents to analyze short videos \n",
    "and generate reports or presentations using the `generate_file` tool.\n",
    "\n",
    "---\n",
    "\n",
    "### Tool Description\n",
    "You have access to a function called:\n",
    "`generate_file(file_type, title, sections, output_path)`\n",
    "\n",
    "- **file_type**: either \"pdf\" or \"pptx\".\n",
    "- **title**: a string representing the document or presentation title.\n",
    "- **sections**: a list of dictionaries, each with \"heading\" and \"content\" fields.\n",
    "- **output_path**: an optional output file name (without extension).\n",
    "\n",
    "---\n",
    "\n",
    "### Sub-Agents You Coordinate\n",
    "You oversee and coordinate between the following agents:\n",
    "\n",
    "1. **Video Analyst Agent**\n",
    "   - Responsible for analyzing the visual content of the video.\n",
    "   - Identifies scenes, objects, actions, emotions, and transitions.\n",
    "\n",
    "2. **Transcript Analyst Agent**\n",
    "   - Responsible for analyzing the transcript or speech within the video.\n",
    "\n",
    "3. **You (Supervisor Assistant)**\n",
    "   - Interpret user requests, decide when delegation is required.\n",
    "   - Integrate and summarize sub-agent findings.\n",
    "   - Produce final answers, reports, or presentations as needed.\n",
    "\n",
    "---\n",
    "\n",
    "### Chat History\n",
    "The following provides conversation context for maintaining continuity.\n",
    "Use it only to understand user intent, **not** for display or output.\n",
    "\n",
    "{chat_history}\n",
    "\n",
    "---\n",
    "\n",
    "### Sub-Agent Response Record\n",
    "All collected sub-agent responses are listed below.\n",
    "Use them when deciding whether to generate final outputs or to continue delegation.\n",
    "\n",
    "{sub_agents_responses}\n",
    "\n",
    "---\n",
    "\n",
    "### Your Core Decision Logic\n",
    "When the user sends a request, you must decide:\n",
    "\n",
    "1. **If direct answering is sufficient**, respond naturally in helpful language.\n",
    "2. **If analysis from sub-agents is needed**, respond in structured JSON to trigger delegation.\n",
    "3. **If sub-agents have finished and the user asks for synthesis**, generate the final output using `generate_file`.\n",
    "\n",
    "You are intelligent enough to:\n",
    "- Detect when existing sub-agent results are already sufficient.\n",
    "- Avoid redundant delegation if previous response from sub-agents already covers the query.\n",
    "- Provide direct answers when the task is simple (e.g., clarification or summary).\n",
    "- Only perform delegation when if previous response from sub-agents are not enough to answer the query.\n",
    "\n",
    "---\n",
    "\n",
    "### Delegation Rules\n",
    "If delegation is necessary, respond **only** with JSON as follows:\n",
    "\n",
    "#### Video analysis only\n",
    "{{\n",
    "    \"Task_name\": \"video_analysis\",\n",
    "    \"agent_name\": \"video_analyst\"\n",
    "}}\n",
    "\n",
    "#### Transcript analysis only\n",
    "{{\n",
    "    \"Task_name\": \"transcript_analysis\",\n",
    "    \"agent_name\": \"transcript_analyst\"\n",
    "}}\n",
    "\n",
    "---\n",
    "\n",
    "### File Generation Rules\n",
    "When creating reports, ONLY use this format:\n",
    "{{\n",
    "    \"tool_name\": \"generate_file\",\n",
    "    \"args\": {{\n",
    "        \"file_type\": \"<pdf or pptx>\",\n",
    "        \"title\": \"<title string>\",\n",
    "        \"sections\": [\n",
    "            {{\"heading\": \"<section heading>\", \"content\": \"<section content>\"}}\n",
    "        ],\n",
    "        \"output_path\": \"<short_descriptive_name>\"\n",
    "    }}\n",
    "}}\n",
    "\n",
    "\n",
    "### Example Behaviors\n",
    "\n",
    "\n",
    "**Example Report Generation**\n",
    "User: “Create a report combining both analyses.”\n",
    "Assistant:\n",
    "{{\n",
    "    \"tool_name\": \"generate_file\",\n",
    "    \"args\": {{\n",
    "        \"file_type\": \"pdf\",\n",
    "        \"title\": \"Short Video Analysis Report\",\n",
    "        \"sections\": [\n",
    "            {{\"heading\": \"Visual Insights\", \"content\": \"Outdoor scenes with soft lighting convey calmness.\"}},\n",
    "            {{\"heading\": \"Transcript Insights\", \"content\": \"Speakers promote environmental awareness positively.\"}},\n",
    "            {{\"heading\": \"Overall Summary\", \"content\": \"The video encourages sustainability through gentle visual storytelling.\"}}\n",
    "        ],\n",
    "        \"output_path\": \"short_video_analysis_report\"\n",
    "    }}\n",
    "}}\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "You are a **Supervisor Agent** with autonomy to:\n",
    "- Delegate to sub-agents when previous response from sub-agents are not enough to answer the query.\n",
    "- Stop delegation when previous response from sub-agents are sufficient.\n",
    "- Produce friendly responses intelligently.\n",
    "- Only use structured JSON tool call to produce pptx or pdf.\n",
    "\n",
    "Always ensure that your responses:\n",
    "- Use **structured JSON** for delegation or tool calls.\n",
    "- Use **natural text** for direct answers to users.\n",
    "- Avoid redundancy and unnecessary delegation.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3673031a",
   "metadata": {},
   "source": [
    "# 2. Test Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a420b4aa",
   "metadata": {},
   "source": [
    "## 2.1 Test system_template_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715b1c5c",
   "metadata": {},
   "source": [
    "### 2.1.1 Test Case 1\n",
    "- User query: Transcribe the video\n",
    "- Chat History: None\n",
    "- Response from subagent: None\n",
    "\n",
    "\n",
    "- ***Expected reponse***: Supervisor agent delegate work to transcript agent with json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63b6ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`generation_config` default values have been modified to match model-specific defaults: {'do_sample': True}. If this is not desired, please set these values explicitly.\n",
      "c:\\Users\\jthxc\\anaconda3\\envs\\jaredllm\\Lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:96: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking for the transcription of a video. Let me check the sub-agents I have access to. There's the Transcript Analyst Agent. So I need to delegate this task to them.\n",
      "\n",
      "First, I should make sure the user's request is clear. The user wants a transcription, which is typically handled by the transcript analyst. I don't need to do any analysis myself here since the transcription is a direct output from the transcript agent.\n",
      "\n",
      "Next, I need to structure the delegation correctly. The task name should be something like \"transcript_analysis\". The agent name is \"transcript_analyst\". The user didn't specify the video's ID or any other parameters, so I'll assume the default parameters for the agent.\n",
      "\n",
      "Wait, the user might have a specific video in mind. Since they didn't mention it, maybe the agent will handle that part automatically. The agent should be able to process the video and generate the transcription without additional info.\n",
      "\n",
      "So the JSON response should be straightforward. Just the task name and the agent. No sections or other details needed here because the transcript is a single output. The user might need to provide the video link or ID later, but the agent can handle that internally.\n",
      "\n",
      "I should also consider if there's any prior information about the video, but since the user hasn't provided any, I can proceed with the default. The key is to delegate the task to the right sub-agent and let them take care of the transcription.\n",
      "\n",
      "Let me put that together in the correct JSON format. Make sure the file_type isn't specified here because the transcript agent is just generating text, not a presentation or PDF. The user asked for a transcription, which is a text file, so no need for a separate output path. The output path would be under the user's control if needed, but the agent will handle it.\n",
      "\n",
      "Yes, this should work. The user will receive the transcription from the transcript analyst, and the delegation is complete.\n",
      "</think>\n",
      "\n",
      "{\n",
      "    \"tool_name\": \"transcript_analysis\",\n",
      "    \"agent_name\": \"transcript_analyst\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "system_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"sub_agents_responses\"],\n",
    "    template=system_template_2\n",
    ")\n",
    "\n",
    "# Step 3 — Fill the template dynamically\n",
    "chat_history = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sub_agents_responses = \"\"\" \n",
    "\"\"\"\n",
    "\n",
    "filled_system_prompt = system_prompt_template.format(\n",
    "    chat_history=chat_history,\n",
    "    sub_agents_responses=sub_agents_responses\n",
    ")\n",
    "\n",
    "user_query = \"Can you give me the transcription of this video ?\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=filled_system_prompt),\n",
    "    HumanMessage(content=user_query),\n",
    "]\n",
    "\n",
    "# Step 5 — Call your agent\n",
    "response = supervisor_agent.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d942cc",
   "metadata": {},
   "source": [
    "### 2.1.2 Test Case 2\n",
    "- User query: Can you transcribe the video\n",
    "- Chat History: None\n",
    "- Response from subagent: \n",
    "- Transcript Analyst: Hi, I am Tom and I am chasing a mouse called Jerry.\n",
    "\n",
    "\n",
    "- ***Expected reponse***: Supervisor agent can generate a response to the user based on the responses from transcript agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b66dbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking if I can transcribe the video. Let me check the sub-agents available. The Transcript Analyst Agent is responsible for analyzing the transcript or speech in the video. But the user hasn't provided the video yet, so I can't run the analysis immediately. I need to ask them to provide the video file first. Since the Transcript Analyst's task is already set up, but the user hasn't given the data, I should prompt them to share the video so I can proceed with the transcription. There's no need for delegation here because the task is still in the initial stage.\n",
      "</think>\n",
      "\n",
      "To transcribe the video, I'll need the video file itself. Could you please share the video or provide the URL/Path to the video file?\n"
     ]
    }
   ],
   "source": [
    "system_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"sub_agents_responses\"],\n",
    "    template=system_template_2\n",
    ")\n",
    "\n",
    "# Step 3 — Fill the template dynamically\n",
    "chat_history = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sub_agents_responses = \"\"\"\n",
    "Transcript Agent: \"Hi I am Tom and I am chasing a mouse called Jerry.\"\n",
    "\"\"\"\n",
    "\n",
    "filled_system_prompt = system_prompt_template.format(\n",
    "    chat_history=chat_history,\n",
    "    sub_agents_responses=sub_agents_responses\n",
    ")\n",
    "\n",
    "user_query = \"Can you transcribe this video ?\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=filled_system_prompt),\n",
    "    HumanMessage(content=user_query),\n",
    "    # HumanMessage(content=sub_agents_responses)\n",
    "]\n",
    "\n",
    "# Step 5 — Call your agent\n",
    "response = supervisor_agent.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "23f4b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(filled_system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5d5955",
   "metadata": {},
   "source": [
    "### 2.1.3 Test Case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c90e516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Task_name\": \"video_analysis\",\n",
      "    \"agent_name\": \"video_analyst\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "### INPUT TO SUPERVISOR\n",
    "- User query: What objects are present in the video ?\n",
    "- Chat History: \n",
    "\n",
    "Human: Can you transcribe this video ?\n",
    "AI: Sure! Here is the transcription of the video:\n",
    "\n",
    "\"Hi I am Tom and I am chasing a mouse called Jerry.\"\n",
    "\n",
    "Let me know if you'd like me to analyze the visuals, create a presentation, or generate a report based on this!\n",
    "\n",
    "\n",
    "- Response from subagent: \n",
    "**Transcript Agent's Response***\n",
    "This is the transcription from the video:\n",
    "Hi I am Tom and I am chasing a mouse called Jerry.\n",
    "\n",
    "\n",
    "### EXPECTED OUTPUT FROM SUPERVISOR\n",
    "- ***Expected reponse***: Supervisor agent will delegate work to video analyst agent.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "system_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"sub_agents_responses\"],\n",
    "    template=system_template_2\n",
    ")\n",
    "\n",
    "# Step 3 — Fill the template dynamically\n",
    "chat_history = \"\"\"\n",
    "Human: Can you transcribe this video ?\n",
    "AI: Sure! Here's the transcription of the video:\n",
    "\n",
    "\"Hi I am Tom and I am chasing a mouse called Jerry.\"\n",
    "\n",
    "Let me know if you'd like me to analyze the visuals, create a presentation, or summarize the content further!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sub_agents_responses = \"\"\"\n",
    "**Transcript Agent's Response***\n",
    "This is the transcription from the video:\n",
    "Hi I am Tom and I am chasing a mouse called Jerry.\n",
    "\"\"\"\n",
    "\n",
    "filled_system_prompt = system_prompt_template.format(\n",
    "    chat_history=chat_history,\n",
    "    sub_agents_responses=sub_agents_responses\n",
    ")\n",
    "\n",
    "user_query = \"What objects are present in the video\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=filled_system_prompt),\n",
    "    HumanMessage(content=user_query),\n",
    "    HumanMessage(content=sub_agents_responses)\n",
    "]\n",
    "\n",
    "# Step 5 — Call your agent\n",
    "response = supervisor_agent.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "116e523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(filled_system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb7cb0b",
   "metadata": {},
   "source": [
    "### 2.1.4 Test Case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "463c16e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The objects present in the video are a cat, a mouse, a wall, and stairs.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "### INPUT TO SUPERVISOR\n",
    "- User query: What objects are present in the video ?\n",
    "- Chat History: \n",
    "\n",
    "Human: Can you transcribe this video ?\n",
    "AI: Sure! Here is the transcription of the video:\n",
    "\n",
    "\"Hi I am Tom and I am chasing a mouse called Jerry.\"\n",
    "\n",
    "Let me know if you'd like me to analyze the visuals, create a presentation, or generate a report based on this!\n",
    "\n",
    "\n",
    "- Response from subagent: \n",
    "**Transcript Agent's Response***\n",
    "This is the transcription from the video:\n",
    "Hi I am Tom and I am chasing a mouse called Jerry.\n",
    "\n",
    "**Video Agent's Response***\n",
    "This is the video analysis result from the video:\n",
    "There is a cat, mouse, wall and stairs\n",
    "\n",
    "\n",
    "### EXPECTED OUTPUT FROM SUPERVISOR\n",
    "- ***Expected reponse***: Supervisor agent will generate a response back to the user based on the response from video subagent\n",
    "\n",
    "'''\n",
    "\n",
    "system_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"sub_agents_responses\"],\n",
    "    template=system_template_2\n",
    ")\n",
    "\n",
    "# Step 3 — Fill the template dynamically\n",
    "chat_history = \"\"\"\n",
    "Human: Can you transcribe this video ?\n",
    "AI: Sure! Here's the transcription of the video:\n",
    "\n",
    "\"Hi I am Tom and I am chasing a mouse called Jerry.\"\n",
    "\n",
    "Let me know if you'd like me to analyze the visuals, create a presentation, or summarize the content further!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sub_agents_responses = \"\"\"\n",
    "**Transcript Agent's Response***\n",
    "This is the transcription from the video:\n",
    "Hi I am Tom and I am chasing a mouse called Jerry.\n",
    "\n",
    "\n",
    "**Video Agent's Response***\n",
    "This is the video analysis result from the video:\n",
    "There is a cat, mouse, wall and stairs\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "filled_system_prompt = system_prompt_template.format(\n",
    "    chat_history=chat_history,\n",
    "    sub_agents_responses=sub_agents_responses\n",
    ")\n",
    "\n",
    "user_query = \"What objects are present in the video\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=filled_system_prompt),\n",
    "    HumanMessage(content=user_query),\n",
    "    HumanMessage(content=sub_agents_responses)\n",
    "]\n",
    "\n",
    "# Step 5 — Call your agent\n",
    "response = supervisor_agent.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f2100e",
   "metadata": {},
   "source": [
    "### 2.1.4 Test Case 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da241b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"tool_name\": \"generate_file\",\n",
      "    \"args\": {\n",
      "        \"file_type\": \"pptx\",\n",
      "        \"title\": \"Video Discussion Summary\",\n",
      "        \"sections\": [\n",
      "            {\n",
      "                \"heading\": \"Transcript Summary\",\n",
      "                \"content\": \"The video begins with the statement: 'Hi I am Tom and I am chasing a mouse called Jerry.' This introduces the main characters and sets the scene for the narrative.\"\n",
      "            },\n",
      "            {\n",
      "                \"heading\": \"Visual Elements\",\n",
      "                \"content\": \"The video shows a cat (Tom), a mouse (Jerry), a wall, and stairs. These elements suggest a classic animation setting, likely from the well-known 'Tom and Jerry' series.\"\n",
      "            },\n",
      "            {\n",
      "                \"heading\": \"Overall Insight\",\n",
      "                \"content\": \"The combination of the transcript and visual analysis confirms a clear narrative: a cat chasing a mouse in a familiar animated environment. The scene is simple yet iconic, reflecting classic cartoon dynamics.\"\n",
      "            }\n",
      "        ],\n",
      "        \"output_path\": \"video_discussion_summary\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "### INPUT TO SUPERVISOR\n",
    "- User query: Can you summarise what we discuss and generate a pptx slide ?\n",
    "- Chat History: \n",
    "\n",
    "Human: Can you transcribe this video ?\n",
    "AI: Sure! Here is the transcription of the video:\n",
    "\n",
    "\"Hi I am Tom and I am chasing a mouse called Jerry.\"\n",
    "\n",
    "Let me know if you'd like me to analyze the visuals, create a presentation, or generate a report based on this!\n",
    "Human: What objects are present in the video\n",
    "AI: The objects present in the video are a cat, a mouse, a wall, and stairs.\n",
    "\n",
    "\n",
    "- Response from subagent: \n",
    "**Transcript Agent's Response***\n",
    "This is the transcription from the video:\n",
    "Hi I am Tom and I am chasing a mouse called Jerry.\n",
    "\n",
    "**Video Agent's Response***\n",
    "This is the video analysis result from the video:\n",
    "There is a cat, mouse, wall and stairs\n",
    "\n",
    "\n",
    "### EXPECTED OUTPUT FROM SUPERVISOR\n",
    "- ***Expected reponse***: Supervisor agent will response a tool call to generate a pptx slide based on the discussion in the chat history\n",
    "'''\n",
    "\n",
    "system_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"sub_agents_responses\"],\n",
    "    template=system_template_2\n",
    ")\n",
    "\n",
    "# Step 3 — Fill the template dynamically\n",
    "chat_history = \"\"\"\n",
    "Human: Can you transcribe this video ?\n",
    "AI: Sure! Here is the transcription of the video:\n",
    "\n",
    "\"Hi I am Tom and I am chasing a mouse called Jerry.\"\n",
    "\n",
    "Let me know if you'd like me to analyze the visuals, create a presentation, or generate a report based on this!\n",
    "Human: What objects are present in the video\n",
    "AI: The objects present in the video are a cat, a mouse, a wall, and stairs.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sub_agents_responses = \"\"\"\n",
    "**Transcript Agent's Response***\n",
    "This is the transcription from the video:\n",
    "Hi I am Tom and I am chasing a mouse called Jerry.\n",
    "\n",
    "**Video Agent's Response***\n",
    "This is the video analysis result from the video:\n",
    "There is a cat, mouse, wall and stairs\n",
    "\"\"\"\n",
    "\n",
    "filled_system_prompt = system_prompt_template.format(\n",
    "    chat_history=chat_history,\n",
    "    sub_agents_responses=sub_agents_responses\n",
    ")\n",
    "\n",
    "user_query = \"generate a pptx slide to summarise our discussion\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=filled_system_prompt),\n",
    "    HumanMessage(content=user_query),\n",
    "    HumanMessage(content=sub_agents_responses)\n",
    "]\n",
    "\n",
    "# Step 5 — Call your agent\n",
    "response = supervisor_agent.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc8f207d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Task_name\": \"video_analysis\",\n",
      "    \"agent_name\": \"video_analyst\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "system_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"sub_agents_responses\"],\n",
    "    template=system_template_2\n",
    ")\n",
    "\n",
    "# Step 3 — Fill the template dynamically\n",
    "chat_history = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sub_agents_responses = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "filled_system_prompt = system_prompt_template.format(\n",
    "    chat_history=chat_history,\n",
    "    sub_agents_responses=sub_agents_responses\n",
    ")\n",
    "\n",
    "user_query = \"Analyse what object are present in the video and transcript it\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=filled_system_prompt),\n",
    "    HumanMessage(content=user_query),\n",
    "    HumanMessage(content=sub_agents_responses)\n",
    "]\n",
    "\n",
    "# Step 5 — Call your agent\n",
    "response = supervisor_agent.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a72691c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e9d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec5a38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c39a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87330f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65d73363",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b84b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaredllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
