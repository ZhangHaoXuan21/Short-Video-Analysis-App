{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47c6ee79",
   "metadata": {},
   "source": [
    "# 1. Design a Transcript Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3842e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\I'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\I'\n",
      "C:\\Users\\jthxc\\AppData\\Local\\Temp\\ipykernel_888\\4113074878.py:1: SyntaxWarning: invalid escape sequence '\\I'\n",
      "  audio_file = \"C:\\Interview Assignment\\Intel GenAI Software Engineer Assessment\\Short-Video-Analyst\\sample_videos\\What is MCP and how does it change AI_ (MCP explained) #ai #artificialintelligence.mp4\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in C:\\Interview Assignment\\Intel GenAI Software Engineer Assessment\\Short-Video-Analyst\\sample_videos\\What is MCP and how does it change AI_ (MCP explained) #ai #artificialintelligence.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Transcription: Everyone in AI is talking about MCP being the next big breakthrough and for good reason. This could move us a step closer to a genetic AI, meaning that AI no longer requires human supervision. MCP stands for Model Context Protocol and it solves a big problem in AI. Everyone knows that LLMs like ChachiPT or Claude are improving all the time, but despite exponential innovation, they still can't escape this one problem. problem and how does MCP actually solve it? Well, AI tools aren't good at directly performing tasks like accessing databases, sending texts or handling online payments. And this is because they don't have direct access and they can't interact with external services. MCP promises to solve this exact problem. Think of it like an interpreter. So if your AI assistant speaks one language and your payment processor speaks another language, MCP acts as the translation allowing both of these to communicate. But why does this actually matter? Well, MCP lets you connect your AI assistant to numerous services through one simple setup and it takes care of most configurations automatically. This means that your AI can't effortlessly book appointments, handle email tasks, and update customer records or even manage payments without human intervention. MCP was originally developed by Anthropic and it has recently gained backing from OpenAI, And this looks likely that this will become the new standard for AI integrations.\n"
     ]
    }
   ],
   "source": [
    "audio_file = \"C:\\Interview Assignment\\Intel GenAI Software Engineer Assessment\\Short-Video-Analyst\\sample_videos\\What is MCP and how does it change AI_ (MCP explained) #ai #artificialintelligence.mp4\"\n",
    "\n",
    "#audio_file = \"C:\\Interview Assignment\\Intel GenAI Software Engineer Assessment\\Short-Video-Analyst\\sample_videos\\cat.mp4\"\n",
    "\n",
    "video_path = \"C:\\Interview Assignment\\Intel GenAI Software Engineer Assessment\\Short-Video-Analyst\\sample_videos\\Son strikes first ðŸš€.mp4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecefb0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transcript_agent import VoiceToText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0610e850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Loading Whisper model: openai/whisper-tiny\n",
      "ðŸ“‚ Model cache directory: c:\\Interview Assignment\\Intel GenAI Software Engineer Assessment\\Short-Video-Analyst\\model\\openai-whisper-tiny\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9221031041b46cdafb4bd2c4b9ff2a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jthxc\\anaconda3\\envs\\jaredllm\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Interview Assignment\\Intel GenAI Software Engineer Assessment\\Short-Video-Analyst\\model\\openai-whisper-tiny\\models--openai--whisper-tiny. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a0e005cac34b38b0391ce7f8c5d3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7ad72e9ea74915ba9ce31de0df3c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe2f3c2a7ca4af7ac102dbde9c27626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93eaf0c88a264e8a826413f1f7c0ccb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8798e7e3fef5471fb348fef6f6b1fcdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a63f14c66f47c98bdc3a24fd403118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5957866fa4423a8704b887f60d59f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05ea73531154818add33554f93f5067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc4ccc3c940400d99165746fc98224a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815a69e990544da6b7764a2078abfae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Whisper model loaded successfully on cuda\n"
     ]
    }
   ],
   "source": [
    "vtt = VoiceToText(model_name=\"openai/whisper-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb65cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\I'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\I'\n",
      "C:\\Users\\jthxc\\AppData\\Local\\Temp\\ipykernel_7856\\2387409496.py:1: SyntaxWarning: invalid escape sequence '\\I'\n",
      "  video_path = \"C:\\Interview Assignment\\Intel GenAI Software Engineer Assessment\\Short-Video-Analyst\\sample_videos\\Son strikes first ðŸš€.mp4\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Loading Whisper model: openai/whisper-tiny\n",
      "ðŸ“‚ Model cache directory: c:\\Interview Assignment\\Intel GenAI Software Engineer Assessment\\Short-Video-Analyst\\model\\openai-whisper-tiny\n",
      "âœ… Whisper model loaded successfully on cuda\n",
      "MoviePy - Writing audio in C:\\Interview Assignment\\Intel GenAI Software Engineer Assessment\\Short-Video-Analyst\\sample_videos\\Robbing a bank in 2028.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "ðŸŽµ Extracted audio to: C:\\Interview Assignment\\Intel GenAI Software Engineer Assessment\\Short-Video-Analyst\\sample_videos\\Robbing a bank in 2028.wav\n",
      "ðŸ§¹ Removed temporary file: C:\\Interview Assignment\\Intel GenAI Software Engineer Assessment\\Short-Video-Analyst\\sample_videos\\Robbing a bank in 2028.wav\n",
      "Transcription: I'm robbing this bank. Don't draw attention to yourself. Me? You're wearing a mask, bro? I mean, call him into his I say. And your kids will see you again tonight. I don't have kids. You're a wife who'll see you again tonight. Not marrying your girlfriend will see you again tonight. I'm gay. I'd be sad if your boyfriend was left alone tonight. I'm single. If you want to live to see another day, then you don't care. I will hurt everybody in here, you know? Be my get your Tristan! Yo! Check the Saudis robbing us. That's so cool, man. You got it, got it? Is that a gun? You mean, shoot me. Right here. Come on, man. Shoot me. You guys are messed up. You two saw for a robber. You think robbers can't be solved. No, they can be solved. They can be hard, too. Yeah, they can't pause. You're that twisted? You hard, man. So that's not a gun, huh? I'm not. Listen, just call empty the safe and you will be safe. Blood, thanks. I have the keys to the safe. You think so? You have the keys to the safe. I'd say there he is, bro. Hey, can I put you on my story? I've just never been robbed before. Yo, tag me, bro.\n"
     ]
    }
   ],
   "source": [
    "video_path = \"C:\\Interview Assignment\\Intel GenAI Software Engineer Assessment\\Short-Video-Analyst\\sample_videos\\Son strikes first ðŸš€.mp4\"\n",
    "\n",
    "video_path= r\"C:\\Interview Assignment\\Intel GenAI Software Engineer Assessment\\Short-Video-Analyst\\sample_videos\\Robbing a bank in 2028.mp4\"\n",
    "\n",
    "try:\n",
    "    vtt = VoiceToText(model_name=\"openai/whisper-tiny\")\n",
    "    text = vtt.transcribe(video_path)  # or \"example.wav\"\n",
    "    print(\"Transcription:\", text)\n",
    "except Exception as e:\n",
    "    print(f\"Error message: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5caeeb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1f0598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaredllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
